{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff134c0",
   "metadata": {},
   "source": [
    "## How gwlearn Differs from MGWR\n",
    "\n",
    "`gwlearn` is a **modern, flexible alternative** to traditional geographically weighted regression libraries like [`mgwr`](https://github.com/pysal/mgwr). While both enable spatial regression analysis, they have fundamentally different design philosophies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad450132",
   "metadata": {},
   "source": [
    "## mgwr architecture:\n",
    "![Current MGWR](https://raw.githubusercontent.com/FirePheonix/mgwrVSgwlearnSVGs/eb291a4a19a6fd6fb0dc1f09a20e9d0c78c36d0d/mgwr_architecture.svg)\n",
    "\n",
    "\n",
    "## gwlearn architecture::\n",
    "\n",
    "![GWLearn Architecture](https://raw.githubusercontent.com/FirePheonix/mgwrVSgwlearnSVGs/eb291a4a19a6fd6fb0dc1f09a20e9d0c78c36d0d/gwlearn_architecture.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e917f453",
   "metadata": {},
   "source": [
    "## Setup: Load Common Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba4dcab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from geodatasets import get_path\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load dataset\n",
    "gdf = gpd.read_file(get_path(\"geoda.guerry\"))\n",
    "X = gdf[['Crm_prp', 'Litercy', 'Donatns', 'Lottery']]\n",
    "y = gdf['Suicids']\n",
    "geom = gdf.representative_point()\n",
    "coords = np.column_stack([geom.x, geom.y])  # For mgwr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d60458",
   "metadata": {},
   "source": [
    "## Both can do: Linear GWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87109ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gwlearn R²: 0.7251  AICc: 2007.4  Time: 0.46s\n",
      "mgwr R²: 0.7251  AICc: 2011.2  Time: 0.08s\n",
      "\n",
      "  mgwr is 5.7x faster for basic linear GWR\n"
     ]
    }
   ],
   "source": [
    "# NOTE: run the same cell twice:\n",
    "# The first gwlearn run includes joblib worker initialization and numerical backend warm-up\n",
    "# subsequent runs reuse these resources, resulting in significantly lower execution time.\n",
    "\n",
    "# gwlearn\n",
    "from gwlearn.linear_model import GWLinearRegression\n",
    "\n",
    "start = time.time()\n",
    "gw = GWLinearRegression(geometry=geom, bandwidth=25, fixed=False)\n",
    "gw.fit(X, y)\n",
    "gw_time = time.time() - start\n",
    "print(f\"gwlearn R²: {metrics.r2_score(y, gw.pred_):.4f}  AICc: {gw.aicc_:.1f}  Time: {gw_time:.2f}s\")\n",
    "\n",
    "# mgwr\n",
    "from mgwr.gwr import GWR\n",
    "\n",
    "start = time.time()\n",
    "mg = GWR(coords, y.values.reshape(-1,1), X.values, bw=25, fixed=False).fit()\n",
    "mg_time = time.time() - start\n",
    "print(f\"mgwr R²: {metrics.r2_score(y, mg.predy):.4f}  AICc: {mg.aicc:.1f}  Time: {mg_time:.2f}s\")\n",
    "\n",
    "print(f\"\\n  mgwr is {gw_time/mg_time:.1f}x faster for basic linear GWR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c352fa",
   "metadata": {},
   "source": [
    "### Why the Timing Difference?\n",
    "\n",
    "\n",
    "**mgwr approach:**\n",
    "- Builds a single block-diagonal weight matrix\n",
    "- Solves weighted least squares using optimized numpy/scipy linear algebra\n",
    "- Computes all local coefficients in ONE vectorized operation\n",
    "- Minimal Python overhead - mostly C-level numpy operations\n",
    "\n",
    "![mgwr_time](https://raw.githubusercontent.com/FirePheonix/mgwrVSgwlearnSVGs/89a10b18ddcd06c88d9108f3f1fc0e4054e641bd/mgwr_time_difference.svg)\n",
    "\n",
    "**gwlearn approach:**\n",
    "- Creates a libpysal.graph.Graph for spatial weights\n",
    "- For each location, clones the sklearn estimator\n",
    "- Dispatches N parallel jobs via joblib \n",
    "    - THIS is the exact step is time expensive because:\n",
    "         Python overhead N times\n",
    "         Each local model:\n",
    "\n",
    "            1.  Calls fit()\n",
    "\n",
    "            2. Validates inputs\n",
    "\n",
    "            3. Handles sample weights\n",
    "\n",
    "            4. Runs sklearn plumbing\n",
    "\n",
    "        Even if each fit is “small”, Python call overhead accumulates. Even thogh each model solves\n",
    "\n",
    "        $\\hat{\\beta} = (X^{\\mathsf T} W_i X)^{-1} X^{\\mathsf T} W_i y$\n",
    "\n",
    "        it become expensive since gwlearn repeats the fitting setup N times.\n",
    " \n",
    "        \n",
    "\n",
    "        \n",
    "- Each job fits an independent sklearn model with sample weights\n",
    "- Aggregates results from all local models\n",
    "\n",
    "![gwlearn_time](https://raw.githubusercontent.com/FirePheonix/mgwrVSgwlearnSVGs/0c9f9bca761d016f24af24fb91de4da2eb571869/gwlearn_time_difference.svg)\n",
    "\n",
    "**mgwr is faster for basic linear GWR** because:\n",
    "\n",
    "| Factor | mgwr | gwlearn |\n",
    "|--------|------|---------|\n",
    "| **Implementation** | Specialized matrix solver | Generic meta-estimator |\n",
    "| **Computation** | Single vectorized WLS | N separate sklearn model fits |\n",
    "| **Overhead** | Minimal (direct numpy) | joblib + sklearn cloning |\n",
    "| **Optimization** | Hand-tuned for GWR | Flexibility over speed |\n",
    "\n",
    "**Key insight**: mgwr solves GWR as ONE matrix equation across all locations simultaneously using optimized linear algebra. gwlearn fits N independent sklearn models (one per location), which adds overhead but enables **any sklearn estimator**.\n",
    "\n",
    "**Trade-off**:\n",
    "-  **Need speed + only linear GWR?** → Use mgwr\n",
    "-  **Need flexibility (Ridge, Lasso, RF, classification)?** → Use gwlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e169a0b",
   "metadata": {},
   "source": [
    "---\n",
    "##  1. Architecture Comparison: API Style\n",
    "\n",
    "**MGWR**: Custom API with coordinate arrays  \n",
    "**gwlearn**: sklearn-compatible API with GeoSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "648ec96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGWR API:\n",
      "- Input: numpy arrays + coordinate matrix\n",
      "- Output: Custom results object\n",
      "- R²: 0.7251\n"
     ]
    }
   ],
   "source": [
    "from mgwr.gwr import GWR\n",
    "\n",
    "# mgwr requires: numpy arrays, coords as separate array, y reshaped\n",
    "mgwr_model = GWR(\n",
    "    coords=coords,                    # Coordinate array (n, 2)\n",
    "    y=y.values.reshape(-1, 1),        # Must reshape to (n, 1)\n",
    "    X=X.values,                       # Feature array\n",
    "    bw=25,\n",
    "    fixed=False,\n",
    "    kernel='bisquare'\n",
    ")\n",
    "mgwr_results = mgwr_model.fit()\n",
    "\n",
    "print(\"MGWR API:\")\n",
    "print(f\"- Input: numpy arrays + coordinate matrix\")\n",
    "print(f\"- Output: Custom results object\")\n",
    "print(f\"- R²: {metrics.r2_score(y, mgwr_results.predy):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a36bb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gwlearn API:\n",
      "- Input: pandas DataFrame + GeoSeries\n",
      "- Output: Fitted estimator with attributes\n",
      "- R²: 0.7251\n"
     ]
    }
   ],
   "source": [
    "from gwlearn.linear_model import GWLinearRegression\n",
    "\n",
    "# gwlearn uses: pandas DataFrames, GeoSeries for geometry\n",
    "gwlearn_model = GWLinearRegression(\n",
    "    geometry=geom,                    # GeoSeries (integrated)\n",
    "    bandwidth=25,\n",
    "    fixed=False,\n",
    "    kernel='bisquare'\n",
    ")\n",
    "gwlearn_model.fit(X, y)               # Standard sklearn .fit(X, y)\n",
    "\n",
    "print(\"gwlearn API:\")\n",
    "print(f\"- Input: pandas DataFrame + GeoSeries\")\n",
    "print(f\"- Output: Fitted estimator with attributes\")\n",
    "print(f\"- R²: {metrics.r2_score(y, gwlearn_model.pred_):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca51c32",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Model Fitting: Same Results, Different Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c3f787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION: gwlearn matches MGWR output\n",
      "Predictions: MATCH\n",
      "Local R²: MATCH\n",
      "Coefficients: MATCH\n",
      "\n",
      "AIC: gwlearn=1960.75  |  mgwr=1960.75\n",
      "BIC: gwlearn=2045.63  |  mgwr=2045.63\n",
      "AICc: gwlearn=2007.43 |  mgwr=2011.20\n"
     ]
    }
   ],
   "source": [
    "from numpy.testing import assert_array_almost_equal, assert_almost_equal\n",
    "\n",
    "print(\"VALIDATION: gwlearn matches MGWR output\")\n",
    "\n",
    "# Predictions\n",
    "assert_array_almost_equal(gwlearn_model.pred_, mgwr_results.predy.flatten())\n",
    "print(\"Predictions: MATCH\")\n",
    "\n",
    "# Local R²\n",
    "assert_array_almost_equal(gwlearn_model.local_r2_, mgwr_results.localR2.flatten())\n",
    "print(\"Local R²: MATCH\")\n",
    "\n",
    "# Coefficients\n",
    "assert_array_almost_equal(gwlearn_model.local_intercept_, mgwr_results.params[:, 0])\n",
    "assert_array_almost_equal(gwlearn_model.local_coef_, mgwr_results.params[:, 1:])\n",
    "print(\"Coefficients: MATCH\")\n",
    "\n",
    "# Information criteria\n",
    "print(f\"\\nAIC: gwlearn={gwlearn_model.aic_:.2f}  |  mgwr={mgwr_results.aic:.2f}\")\n",
    "print(f\"BIC: gwlearn={gwlearn_model.bic_:.2f}  |  mgwr={mgwr_results.bic:.2f}\")\n",
    "print(f\"AICc: gwlearn={gwlearn_model.aicc_:.2f} |  mgwr={mgwr_results.aicc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5157ca",
   "metadata": {},
   "source": [
    "## Reason for difference in AICc values:\n",
    "\n",
    "The corrected Akaike Information Criterion (AICc) is defined as:\n",
    "\n",
    "$\\mathrm{AICc} = \\mathrm{AIC} + \\frac{2k(k+1)}{n - k - 1}$\n",
    "\n",
    "\n",
    "where:\n",
    "- \\( n \\) is the number of observations  \n",
    "- \\( k \\) is the effective number of model parameters  \n",
    "\n",
    "**Key point:**  \n",
    "Although `gwlearn` and `mgwr` produce *identical predictions, coefficients, and likelihood-based metrics (AIC, BIC)*, their AICc values may differ slightly.\n",
    "\n",
    "This discrepancy arises from **different definitions of the effective degrees of freedom (\\(k\\))**:\n",
    "- `mgwr` estimates \\(k\\) using **hat-matrix trace–based measures**, which are more conservative.\n",
    "- `gwlearn` uses a **simpler estimator-aligned parameter count**, resulting in a slightly smaller \\(k\\).\n",
    "\n",
    "As a result, AICc values can differ by a small margin even when the fitted models are numerically identical. This difference reflects **model complexity accounting**, not a difference in model fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f484d3f",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Model Support Comparison\n",
    "\n",
    "**MGWR**: Only linear regression  \n",
    "**gwlearn**: Any sklearn estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc79281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GW-Ridge R²: 0.1235\n"
     ]
    }
   ],
   "source": [
    "# gwlearn: GW-Ridge (impossible in MGWR)\n",
    "\n",
    "from gwlearn.base import BaseRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "gw_ridge = BaseRegressor(\n",
    "    model=Ridge,\n",
    "    geometry=geom,\n",
    "    bandwidth=25,\n",
    "    fixed=False,\n",
    "    alpha=1.0  # Regularization parameter passed to Ridge\n",
    ")\n",
    "gw_ridge.fit(X, y)\n",
    "\n",
    "print(f\"GW-Ridge R²: {metrics.r2_score(y, gw_ridge.pred_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89303ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GW-Lasso R²: 0.1230\n"
     ]
    }
   ],
   "source": [
    "# gwlearn: GW-Lasso (impossible in MGWR)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "gw_lasso = BaseRegressor(\n",
    "    model=Lasso,\n",
    "    geometry=geom,\n",
    "    bandwidth=25,\n",
    "    fixed=False,\n",
    "    alpha=0.1\n",
    ")\n",
    "gw_lasso.fit(X, y)\n",
    "\n",
    "print(f\"GW-Lasso R²: {metrics.r2_score(y, gw_lasso.pred_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac88b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GW-RandomForest Accuracy: 0.6941\n",
      "Models fitted: 85/85\n"
     ]
    }
   ],
   "source": [
    "# gwlearn: GW-RandomForest Classification (impossible in MGWR)\n",
    "\n",
    "from gwlearn.ensemble import GWRandomForestClassifier\n",
    "\n",
    "# Create binary target for classification\n",
    "y_binary = (y > y.median()).astype(int)\n",
    "\n",
    "gw_rf = GWRandomForestClassifier(\n",
    "    geometry=geom,\n",
    "    bandwidth=40,\n",
    "    fixed=False,\n",
    "    n_estimators=50,\n",
    "    random_state=42\n",
    ")\n",
    "gw_rf.fit(X, y_binary)\n",
    "\n",
    "mask = ~gw_rf.pred_.isna()\n",
    "print(f\"GW-RandomForest Accuracy: {metrics.accuracy_score(y_binary[mask], gw_rf.pred_[mask]):.4f}\")\n",
    "print(f\"Models fitted: {mask.sum()}/{len(mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc263ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GW-GradientBoosting Accuracy: 0.6588\n",
      "Models fitted: 85/85\n",
      "(Completely impossible in MGWR)\n"
     ]
    }
   ],
   "source": [
    "# gwlearn: GW-GradientBoosting Classification (impossible in MGWR)\n",
    "\n",
    "from gwlearn.ensemble import GWGradientBoostingClassifier\n",
    "\n",
    "gw_gb = GWGradientBoostingClassifier(\n",
    "    geometry=geom,\n",
    "    bandwidth=40,\n",
    "    fixed=False,\n",
    "    n_estimators=50,\n",
    "    random_state=42\n",
    ")\n",
    "gw_gb.fit(X, y_binary)\n",
    "\n",
    "mask = ~gw_gb.pred_.isna()\n",
    "print(f\"GW-GradientBoosting Accuracy: {metrics.accuracy_score(y_binary[mask], gw_gb.pred_[mask]):.4f}\")\n",
    "print(f\"Models fitted: {mask.sum()}/{len(mask)}\")\n",
    "print(\"(Completely impossible in MGWR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31e443",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Kernel Weighting Comparison\n",
    "\n",
    "Both support similar kernels, but gwlearn integrates with libpysal.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e02a143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel comparison across libraries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel</th>\n",
       "      <th>R²</th>\n",
       "      <th>AICc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>triangular</td>\n",
       "      <td>0.723878</td>\n",
       "      <td>2003.382362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parabolic</td>\n",
       "      <td>0.630305</td>\n",
       "      <td>1993.697495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bisquare</td>\n",
       "      <td>0.725147</td>\n",
       "      <td>2007.433836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tricube</td>\n",
       "      <td>0.703052</td>\n",
       "      <td>2005.984826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cosine</td>\n",
       "      <td>0.648737</td>\n",
       "      <td>1995.075608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boxcar</td>\n",
       "      <td>0.507931</td>\n",
       "      <td>1981.012221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kernel        R²         AICc\n",
       "0  triangular  0.723878  2003.382362\n",
       "1   parabolic  0.630305  1993.697495\n",
       "2    bisquare  0.725147  2007.433836\n",
       "3     tricube  0.703052  2005.984826\n",
       "4      cosine  0.648737  1995.075608\n",
       "5      boxcar  0.507931  1981.012221"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Available kernels in gwlearn\n",
    "kernels = ['triangular', 'parabolic', 'bisquare', 'tricube', 'cosine', 'boxcar']\n",
    "\n",
    "print(\"Kernel comparison across libraries:\")\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    gw = GWLinearRegression(geometry=geom, bandwidth=25, fixed=False, kernel=kernel)\n",
    "    gw.fit(X, y)\n",
    "    r2 = metrics.r2_score(y, gw.pred_)\n",
    "    results.append({'Kernel': kernel, 'R²': r2, 'AICc': gw.aicc_})\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27006694",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Bandwidth Search Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "686f2071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGWR Bandwidth Search:\n",
      "Optimal bandwidth: 70.0\n",
      "Time: 0.57s\n",
      "Criterion: AICc only\n"
     ]
    }
   ],
   "source": [
    "# MGWR: Bandwidth selection (Sel_BW)\n",
    "\n",
    "from mgwr.sel_bw import Sel_BW\n",
    "\n",
    "start = time.time()\n",
    "mgwr_selector = Sel_BW(coords, y.values.reshape(-1, 1), X.values, fixed=False, kernel='bisquare')\n",
    "mgwr_optimal_bw = mgwr_selector.search(criterion='AICc')\n",
    "mgwr_time = time.time() - start\n",
    "\n",
    "print(f\"MGWR Bandwidth Search:\")\n",
    "print(f\"Optimal bandwidth: {mgwr_optimal_bw}\")\n",
    "print(f\"Time: {mgwr_time:.2f}s\")\n",
    "print(f\"Criterion: AICc only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09b2f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gwlearn Bandwidth Search:\n",
      "Optimal bandwidth: 69\n",
      "Time: 3.93s\n",
      "Criterion: Flexible (aicc, aic, bic, log_loss, custom)\n",
      "Methods: golden_section, interval\n"
     ]
    }
   ],
   "source": [
    "# gwlearn: BandwidthSearch (more flexible)\n",
    "\n",
    "from gwlearn.search import BandwidthSearch\n",
    "\n",
    "start = time.time()\n",
    "gwlearn_search = BandwidthSearch(\n",
    "    GWLinearRegression,\n",
    "    geometry=geom,\n",
    "    fixed=False,\n",
    "    kernel='bisquare',\n",
    "    search_method='golden_section',  # or 'interval'\n",
    "    criterion='aicc',                 # Can also use: 'aic', 'bic', 'log_loss', custom\n",
    "    min_bandwidth=10,\n",
    "    max_bandwidth=80,\n",
    ")\n",
    "gwlearn_search.fit(X, y)\n",
    "gwlearn_time = time.time() - start\n",
    "\n",
    "print(f\"\\ngwlearn Bandwidth Search:\")\n",
    "print(f\"Optimal bandwidth: {gwlearn_search.optimal_bandwidth_}\")\n",
    "print(f\"Time: {gwlearn_time:.2f}s\")\n",
    "print(f\"Criterion: Flexible (aicc, aic, bic, log_loss, custom)\")\n",
    "print(f\"Methods: golden_section, interval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b753d98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interval Search Results:\n",
      "15    2112.050494\n",
      "20    2032.033644\n",
      "25    2007.433836\n",
      "30    1991.763417\n",
      "35    1983.540290\n",
      "40    1978.314198\n",
      "45    1974.192606\n",
      "50    1971.369979\n",
      "55    1970.657519\n",
      "60    1969.622931\n",
      "Name: aicc, dtype: float64\n",
      "\n",
      "Optimal bandwidth: 60\n"
     ]
    }
   ],
   "source": [
    "# gwlearn: Interval search with multiple metrics\n",
    "interval_search = BandwidthSearch(\n",
    "    GWLinearRegression,\n",
    "    geometry=geom,\n",
    "    fixed=False,\n",
    "    search_method='interval',\n",
    "    criterion='aicc',\n",
    "    metrics=['aic', 'bic'],  # Track additional metrics\n",
    "    min_bandwidth=15,\n",
    "    max_bandwidth=60,\n",
    "    interval=5,\n",
    ")\n",
    "interval_search.fit(X, y)\n",
    "\n",
    "print(\"\\nInterval Search Results:\")\n",
    "print(interval_search.scores_)\n",
    "print(f\"\\nOptimal bandwidth: {interval_search.optimal_bandwidth_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bbf17e",
   "metadata": {},
   "source": [
    "##  6. Parallelization Comparison\n",
    "(run this cell more than once to see consistent, accurate timing results without warm up time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8edd79c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gwlearn Parallelization:\n",
      "Single-threaded (n_jobs=1): 0.923s\n",
      "Parallel (n_jobs=-1):       0.430s\n",
      "Speedup: 2.1x\n",
      "\n",
      " Note: MGWR has limited parallelization support\n"
     ]
    }
   ],
   "source": [
    "# gwlearn with n_jobs=1 (single-threaded)\n",
    "start = time.time()\n",
    "gw_single = GWLinearRegression(geometry=geom, bandwidth=25, fixed=False, n_jobs=1)\n",
    "gw_single.fit(X, y)\n",
    "single_time = time.time() - start\n",
    "\n",
    "# gwlearn with n_jobs=-1 (all cores)\n",
    "start = time.time()\n",
    "gw_parallel = GWLinearRegression(geometry=geom, bandwidth=25, fixed=False, n_jobs=-1)\n",
    "gw_parallel.fit(X, y)\n",
    "parallel_time = time.time() - start\n",
    "\n",
    "print(f\"gwlearn Parallelization:\")\n",
    "print(f\"Single-threaded (n_jobs=1): {single_time:.3f}s\")\n",
    "print(f\"Parallel (n_jobs=-1):       {parallel_time:.3f}s\")\n",
    "print(f\"Speedup: {single_time/parallel_time:.1f}x\")\n",
    "print(f\"\\n Note: MGWR has limited parallelization support\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gwlearn venv)",
   "language": "python",
   "name": "gwlearn-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
